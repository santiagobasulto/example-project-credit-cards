{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: red; color: white; padding: 20px;\">\n",
    "    <h1>Example project</h1>\n",
    "Use the red boxes as guide and main sections for your project.\n",
    "<br><br>\n",
    "This project should be subdivided in the following sections that you have to complete:\n",
    "    <b>\n",
    "    <ol>\n",
    "        <li>Project presentation</li>\n",
    "        <li>Data exploration and cleaning</li>\n",
    "        <li>Data visualization</li>\n",
    "        <li>Feature engineering</li>\n",
    "        <li>Predictive modeling</li>\n",
    "        <li>Present results</li>\n",
    "    </ol>\n",
    "    </b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: red; color: white; padding: 20px;\">\n",
    "    <h1>1. Project presentation</h1>\n",
    "    <ul>\n",
    "        <li>1.1. Project objectives</li>\n",
    "        <li>1.2. Form hypotheses about your defined problem and visually analyze the data</li>\n",
    "        <li>1.3. Dataset info, source of the data, columns explanation</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Project presentation\n",
    "### Credit card applications\n",
    "\n",
    "<img src=\"img/creditcard.png\"\n",
    "    style=\"width:250px; float: right; margin: 0 40px 40px 40px;\"></img>\n",
    "\n",
    "In this project you will create a model to predict if an credit card application should be approved or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.1. Project objectives\n",
    "\n",
    "    - Practice classification models\n",
    "    - Practice spot-checking algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2. Form hypotheses about your defined problem and visually analyze the data\n",
    "\n",
    "TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.3. Dataset info\n",
    "\n",
    "To train our model you will use the the [Credit Card Approval dataset](https://archive.ics.uci.edu/ml/datasets/credit+approval) from the UCI MAchine Learning Repository.\n",
    "\n",
    "This file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data.\n",
    "\n",
    "Here's the possible values for each variable:\n",
    "- A1: b, a.\n",
    "- A2: continuous.\n",
    "- A3: continuous.\n",
    "- A4: u, y, l, t.\n",
    "- A5: g, p, gg.\n",
    "- A6: c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n",
    "- A7: v, h, bb, j, n, z, dd, ff, o.\n",
    "- A8: continuous.\n",
    "- A9: t, f.\n",
    "- A10: t, f.\n",
    "- A11: continuous.\n",
    "- A12: t, f.\n",
    "- A13: g, p, s.\n",
    "- A14: continuous.\n",
    "- A15: continuous.\n",
    "- A16: +,- (class attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands on! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: red; color: white; padding: 20px;\">\n",
    "    <h1>2. Data exploration and cleaning</h1>\n",
    "    <ul>\n",
    "        <li>2.1. Gather data</li>\n",
    "        <li>2.2. Fix inconsistencies and handle missing values</li>\n",
    "        <li>2.3. Drop unused columns</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data exploration and cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.1. Gather data\n",
    "\n",
    "Load the `data/credit_approval.csv` file, and store it into `applications_df` DataFrame.\n",
    "\n",
    "This file already has wrong observations removed, and it is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "applications_df = pd.read_csv('data/credit_approval.csv', header=None)\n",
    "\n",
    "applications_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> According to this [blog](http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html) the probable feature names could be `Gender`, `Age`, `Debt`, `Married`, `BankCustomer`, `EducationLevel`, `Ethnicity`, `YearsEmployed`, `PriorDefault`, `Employed`, `CreditScore`, `DriversLicense`, `Citizen`, `ZipCode`, `Income` and `ApprovalStatus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Gender', 'Age', 'Debt', 'Married', 'BankCustomer', 'EducationLevel',\n",
    "        'Ethnicity', 'YearsEmployed', 'PriorDefault', 'Employed', 'CreditScore',\n",
    "        'DriversLicence', 'Citizen', 'ZipCode', 'Income', 'ApprovalStatus']\n",
    "\n",
    "applications_df.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the shape of the resulting `applications_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "applications_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration\n",
    "\n",
    "Let's first see a quick summary of the DataFrame and some descriptive statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "print(applications_df.info())\n",
    "\n",
    "applications_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The dataset contains both numeric and non-numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2. Fix inconsistencies and handle missing values\n",
    "\n",
    "### Detecting missing values\n",
    "\n",
    "Check per column if there is any missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "applications_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting incorrect values\n",
    "\n",
    "Although we don't have missing values, probably there are incorrect values.\n",
    "\n",
    "Let's check the unique values per column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "for col in applications_df.columns:\n",
    "    print(applications_df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled missing values\n",
    "\n",
    "There are many missing values labeled with a '`?`' character.\n",
    "\n",
    "Let's replace these question marks with `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "applications_df.replace('?', np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong column type\n",
    "\n",
    "`Age` column should be of type `float`, fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "applications_df = applications_df.astype({'Age': 'float'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "If we now remove missing values our machine learning model may miss out on information about the dataset that may be useful for its training. Then, there are many models which cannot handle missing values implicitly.\n",
    "\n",
    "So, to avoid this problem, we are going to **impute the missing values with a mean imputation** strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "applications_df.fillna(applications_df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this mean imputation strategy only works on numeric data. So... what about the non-numeric columns?\n",
    "\n",
    "We are going to impute these non-numeric columns with the **most frequent values** as present in the respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "for col in applications_df.columns:\n",
    "    if applications_df[col].dtypes == 'object':\n",
    "        applications_df.fillna(applications_df[col].value_counts().index[0],\n",
    "                               inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, verify the number of `NaN`s again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "applications_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.3. Drop unused columns\n",
    "\n",
    "The `DriversLicense` and `ZipCode` columns are not as important as the other features for our goal of predicting whether to approve an application or not.\n",
    "\n",
    "Let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "applications_df.drop(['DriversLicence', 'ZipCode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: red; color: white; padding: 20px;\">\n",
    "    <h1>3. Data visualization</h1>\n",
    "    <ul>\n",
    "        <li>3.1. Numeric variables analysis</li>\n",
    "        <li>3.2. Non-numeric variables analysis</li>\n",
    "        <li>3.3. Other charts to show relationships between columns</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.1. Numeric variables analysis\n",
    "\n",
    "Let's plot histograms for each numeric variable.\n",
    "\n",
    "First define a `plot_hist` function that receives a column name as parameter and plot an histogram of that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "def plot_hist(col):\n",
    "    applications_df.loc[:,col].plot(kind='hist', title=col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the function above to show an histogram for each numeric column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "numeric_cols = ['Age', 'Debt', 'YearsEmployed', 'CreditScore', 'Income']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plot_hist(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a scatter matrix to see if there is any important relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "ax = scatter_matrix(applications_df[['Age', 'Debt', 'YearsEmployed',\n",
    "                                     'CreditScore', 'Income']],\n",
    "                    figsize=(12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a correlation matrix for all the numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "corr_metrics = applications_df.corr()\n",
    "\n",
    "corr_metrics.style.background_gradient(cmap=\"bwr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numeric columns don't have strong correlation between them.\n",
    "\n",
    "The highest one indicates that more `Age` implies more `YearsEmployed` that at certain point makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2. Non-numeric variables analysis\n",
    "\n",
    "Let's plot bar plots for each non-numeric variable.\n",
    "\n",
    "First define a `plot_bar` function that receives a column name as parameter and plot a bar plot of that column:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "def plot_bar(col):\n",
    "    applications_df.loc[:,col].value_counts().plot(kind='bar', title=col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the function above to show an histogram for each non-numeric column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "non_numeric_cols = ['Gender', 'Married', 'BankCustomer', 'EducationLevel',\n",
    "                    'Ethnicity', 'PriorDefault', 'Employed', 'Citizen',\n",
    "                    'ApprovalStatus']\n",
    "\n",
    "for col in non_numeric_cols:\n",
    "    plot_bar(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3. Other charts to show relationships between columns\n",
    "\n",
    "TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: red; color: white; padding: 20px;\">\n",
    "    <h1>4. Feature engineering</h1>\n",
    "    <ul>\n",
    "        <li>4.1. Select features you will use</li>\n",
    "        <li>4.2. Parse variables to correct data type</li>\n",
    "        <li>4.3. Scale/standardize variables</li>\n",
    "        <li>4.4. Construct meaningful variables using the data you have</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.1. Select features you will use\n",
    "\n",
    "**Create features $X$ and labels $y$**\n",
    "\n",
    "Separate features and labels into different $X$ and $y$ variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "X = applications_df.drop(['ApprovalStatus'], axis=1)\n",
    "y = applications_df['ApprovalStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.2. Parse varaibles to correct data type\n",
    "\n",
    "#### Convert non-numeric data into numeric\n",
    "\n",
    "Let's use `OrdinalEncoder` to encode categorical features ($X$) into integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "non_numeric_cols = ['Gender', 'Married', 'BankCustomer', 'EducationLevel',\n",
    "                    'Ethnicity', 'PriorDefault', 'Employed', 'Citizen']\n",
    "\n",
    "enc = OrdinalEncoder().fit(X[non_numeric_cols])\n",
    "\n",
    "new_values = enc.transform(X[non_numeric_cols])\n",
    "\n",
    "X.loc[:, non_numeric_cols] = new_values\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.3. Scale/standardize variables\n",
    "\n",
    "Let's use `StandardScaler` to rescale the features so that they'll have the properties of a standard normal distribution with $\\mu=0$ and $\\sigma=1$, where $\\mu$ is the mean (average) and $\\sigma$ is the standard deviation from the mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target variable analysis\n",
    "\n",
    "The `ApprovalStatus` is our target variable (label). It has two possible values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.values[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar('ApprovalStatus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `LabelEncoder` to normalize its values such that theye contain only values 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_enc = LabelEncoder().fit(y)\n",
    "\n",
    "y = label_enc.transform(y)\n",
    "\n",
    "y[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.4. Construct meaningful variables using the data you have\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: red; color: white; padding: 20px;\">\n",
    "    <h1>5. Predictive modeling</h1>\n",
    "    <ul>\n",
    "        <li>5.1. Train ML models</li>\n",
    "        <li>5.2. Find best performing model</li>\n",
    "        <li>5.3. Evaluate model</li>\n",
    "        <li>5.3. Use them to make predictions</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.1. Train ML models\n",
    "\n",
    "Create a `get_cv_scores` function that receives a `model` parameter with a scikit-learn model and returns the CV scores of that model.\n",
    "\n",
    "You should use a `StratifiedKFold` cross-validator with 5 splits and a `random_state` seed to get always the same partitions. \n",
    "\n",
    "5 scores should be returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "\n",
    "def get_cv_scores(model):\n",
    "    return cross_val_score(model, X, y,\n",
    "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Spot-check algorithms\n",
    "\n",
    "Create each of the following models and call the `get_cv_scores` function using each model to get its CV scores.\n",
    "\n",
    "Save the resulting scores in the `results_df` to compare them at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "results_df['KNN'] = get_cv_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC(gamma='auto',\n",
    "                random_state=10)\n",
    "\n",
    "results_df['SVM'] = get_cv_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "results_df['Naive Bayes'] = get_cv_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=10)\n",
    "\n",
    "results_df['GBC'] = get_cv_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost Classifier (Adaptive Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(random_state=10)\n",
    "\n",
    "results_df['AdaBoost'] = get_cv_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.2. Find best performing model\n",
    "\n",
    "Show a boxplot per algorithm using the data you saved in `results_df`.\n",
    "\n",
    "Which one performs the best? And the worst?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "results_df.boxplot(figsize=(14,6), grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can do better. We can select the best model and perform a grid search of the model parameters to improve the model's ability to predict credit card approvals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation\n",
    "\n",
    "Train severals 'KNeighborsClassifier' models with different `k` values and calculate the accuracy of these models.\n",
    "\n",
    "Keep using a `KNeighborsClassifier` estimator and a `StratifiedKFold` cross-validator with 5 splits.\n",
    "\n",
    "Test the following `k` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "def get_kneighbors_score(k):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(model, X, y, cv=5)\n",
    "    return scores.mean()\n",
    "\n",
    "ACC_dev = []\n",
    "parameters=[1, 3, 5, 8, 10, 12, 15, 18, 20, 25, 30, 50,60,80,90,100]\n",
    "    \n",
    "for k in parameters:\n",
    "    scores=get_kneighbors_score(k)\n",
    "    ACC_dev.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "# This is one possible solution\n",
    "ACC_dev=pd.DataFrame(ACC_dev)\n",
    "ACC_dev.rename(columns={0: 'Accuracy'}, inplace=True)\n",
    "ACC_dev['parameters']=parameters\n",
    "\n",
    "ACC_dev.loc[ACC_dev['Accuracy'] == ACC_dev['Accuracy'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.3. Evaluate model\n",
    "\n",
    "Create the final model, with the tunned parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get model CV predictions\n",
    "\n",
    "Generate cross-validated estimates for each input data point.\n",
    "\n",
    "Use a `StratifiedKFold` cross-validator with 5 splits and a random_state seed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(model, X, y,\n",
    "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report\n",
    "\n",
    "Show a `classification_report` using the `y_pred` predictions.\n",
    "\n",
    "Remember that our labels were encoded as follow:\n",
    "\n",
    "| type  | code |\n",
    "|-------|------|\n",
    "|   +   |   0  |\n",
    "|   -   |   1  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: red; color: white; padding: 20px;\">\n",
    "    <h1>6. Present results</h1>\n",
    "    <ul>\n",
    "        <li>6.1. Communicate the findings using visualizations</li>\n",
    "        <li>6.2. Final conclusions</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Present results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.1. Communicate the findings using visualizations\n",
    "\n",
    "TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.2. Final conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "\n",
    "Show a `confusion_matrix` using the `y_pred` predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_type": "solution"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y, y_pred, labels=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The first element of the of the first row of the confusion matrix denotes the \n",
    "**true positives** meaning the number of positive instances (approved applications) predicted by the model correctly.\n",
    "\n",
    "> The last element of the second row of the confusion matrix denotes the **true negatives** meaning the number of negative instances (denied applications) predicted by the model correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
